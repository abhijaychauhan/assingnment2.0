{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t286rdaboCHd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('/Creditcard_data.csv')\n",
        "\n",
        "# Analyze class distribution\n",
        "class_counts = dataset['Class'].value_counts()\n",
        "print(f\"Class distribution before balancing:\\n{class_counts}\\n\")\n",
        "\n",
        "# Separate features and target\n",
        "X = dataset.drop(columns=['Class'])\n",
        "y = dataset['Class']\n",
        "\n",
        "# Apply SMOTE to address imbalance\n",
        "oversampler = SMOTE(random_state=101)\n",
        "X_resampled, y_resampled = oversampler.fit_resample(X, y)\n",
        "\n",
        "# Convert resampled data to DataFrame\n",
        "balanced_data = pd.DataFrame(X_resampled, columns=X.columns)\n",
        "balanced_data['Class'] = y_resampled\n",
        "\n",
        "# Define fractions for subset sampling\n",
        "subset_ratios = [0.9, 0.7, 0.5, 0.3, 0.1]\n",
        "\n",
        "# Generate sampled datasets\n",
        "sampled_datasets = [balanced_data.sample(frac=ratio, random_state=101) for ratio in subset_ratios]\n",
        "\n",
        "# Define a collection of models\n",
        "models_to_test = {\n",
        "    'GradientBoosting': GradientBoostingClassifier(random_state=101),\n",
        "    'NaiveBayes': GaussianNB(),\n",
        "    'DecisionTree': DecisionTreeClassifier(random_state=101)\n",
        "}\n",
        "\n",
        "# Initialize list to store results\n",
        "model_performance = []\n",
        "\n",
        "# Evaluate each model on each subset\n",
        "for sample_idx, sampled_data in enumerate(sampled_datasets, start=1):\n",
        "    X_sample = sampled_data.drop(columns=['Class'])\n",
        "    y_sample = sampled_data['Class']\n",
        "\n",
        "    # Train-test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.25, random_state=101)\n",
        "\n",
        "    for model_name, model in models_to_test.items():\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = model.predict(X_test)\n",
        "\n",
        "        # Calculate R^2 score\n",
        "        r2_value = r2_score(y_test, predictions)\n",
        "\n",
        "        # Append results\n",
        "        model_performance.append({\n",
        "            'Subset': f'Subset{sample_idx}',\n",
        "            'Model': model_name,\n",
        "            'R2_Score': r2_value\n",
        "        })\n",
        "\n",
        "# Convert results into a DataFrame for analysis\n",
        "performance_df = pd.DataFrame(model_performance)\n",
        "\n",
        "# Print the evaluation results\n",
        "print(\"Model Evaluation Results:\\n\")\n",
        "print(performance_df)\n",
        "\n",
        "# Identify the best model and subset combination for each model\n",
        "best_configurations = performance_df.loc[performance_df.groupby('Model')['R2_Score'].idxmax()]\n",
        "print(\"\\nBest Configurations by Model:\\n\")\n",
        "print(best_configurations)\n"
      ]
    }
  ]
}